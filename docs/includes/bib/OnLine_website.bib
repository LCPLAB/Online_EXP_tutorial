
@article{chenInvestigatingObjectOrientation2018,
  title = {Investigating {{Object Orientation Effects Across}} 14 {{Languages}}},
  author = {Chen, Sau-Chin and Szabelska, Anna and Chartier, Christopher R. and Kekecs, Zoltan and Lynott, Dermot and Bernabeu, Pablo and Jones, Benedict C. and DeBruine, Lisa and Levitan, Carmel and Werner, Kaitlyn M. and Wang, Kelly and Milyavskaya, Marina and Musser, Erica D. and Papadatou-Pastou, Marietta and Coles, Nicholas and Janssen, Steve and Ozdogru, Asil and Storage, Daniel and Manley, Harry and Brown, Benjamin T. and Barzykowski, Krystian and Evans, Thomas Rhys and Oberzaucher, Elisabeth and Li, Manyu and Vaughn, Leigh Ann and Aczel, Balazs and Attila, Szűts and Batres, Carlota and Chopik, William J. and Peters, Kim Olivia and Olsen, Jerome and Voracek, Martin and Tamnes, Christian Krog and Sirota, Miroslav and Liu, Dawn and Williams, Glenn Patrick and Parganiha, Arti and Chandel, Priyanka and Singh, Margaret Messiah and Tan, Chrystalle B. Y. and Protzko and Arnal, Jack and Stieger, Stefan and Liuzza, Marco Tullio and Kačmár, Pavol and Bavolar, Jozef and Baník, Gabriel and Adamkovic, Matus and Ropovik, Ivan and Babincak, Peter and Seehuus, Martin and Kovic, Vanja and Schmidt, Kathleen},
  date = {2018-11-01T11:29:06},
  doi = {10.31234/osf.io/t2pjv},
  url = {https://psyarxiv.com/t2pjv/},
  urldate = {2018-11-17},
  abstract = {Mental simulation theories of language comprehension propose that people automatically create mental representations of real objects. Evidence from sentence-picture verification tasks has shown that people mentally represent various visual properties such as shape, color, and size. However, the evidence for mental simulations of object orientation is limited. We report a study that investigates the match advantage of object orientation across speakers of different languages. This multi-laboratory project aims to achieve two objectives. First, we examine the replicability of the match advantage of object orientation across multiple languages and laboratories. Second, we will use a mental rotation task to measure participants’ mental imagery after the sentence-picture verification task. The relationship between the participants’ performance of the two tasks will provide a cross-linguistic examination of perceptual simulation processes. With the (broad) evaluation of individual mental imagery ability and potential linguistic moderators, we expect a robust estimation of match advantage of object orientation.},
  file = {D\:\\core\\reading\\preprints\\Chen 等。 - 2018 - Investigating Object Orientation Effects Across 14.pdf;D\:\\core\\reading\\preprints\\Chen 等。 - 2018 - Investigating Object Orientation Effects Across 14.pdf}
}

@article{connellRepresentingObjectColour2007,
  title = {Representing Object Colour in Language Comprehension},
  author = {Connell, Louise},
  date = {2007-03},
  journaltitle = {Cognition},
  volume = {102},
  pages = {476--485},
  issn = {0010-0277},
  doi = {10.1016/j.cognition.2006.02.009},
  abstract = {Embodied theories of cognition hold that mentally representing something red engages the neural subsystems that respond to environmental perception of that colour. This paper examines whether implicit perceptual information on object colour is represented during sentence comprehension even though doing so does not necessarily facilitate task performance. After reading a sentence that implied a particular colour for a given object, participants were presented with a picture of the object that either matched or mismatched the implied colour. When asked if the pictured object was mentioned in the preceding sentence, people’s responses were faster when the colours mismatched than when they matched, suggesting that object colour is represented differently to other object properties such as shape and orientation. A distinction between stable and unstable embodied representations is proposed to allow embodied theories to account for these findings.},
  keywords = {Colour,embodied cognition,Language comprehension,mental representation,Perception,Stability},
  file = {D\:\\core\\reading\\cognition\\1-s2.0-S0010027706000606-main.pdf;D\:\\core\\reading\\cognition\\1-s2.0-S0010027706000606-main.pdf}
}

@article{langeJustAnotherTool2015,
  title = {"{{Just Another Tool}} for {{Online Studies}}” ({{JATOS}}):  {{An}} Easy Solution for Setup and Management of Web Servers Supporting Online Studies},
  shorttitle = {"{{Just Another Tool}} for {{Online Studies}}” ({{JATOS}})},
  author = {Lange, Kristian and Kühn, Simone and Filevich, Elisa},
  date = {2015-06-26},
  journaltitle = {PLOS ONE},
  shortjournal = {PLOS ONE},
  volume = {10},
  number = {6},
  pages = {e0130834},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0130834},
  url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0130834},
  urldate = {2020-11-23},
  abstract = {We present here “Just Another Tool for Online Studies” (JATOS): an open source, cross-platform web application with a graphical user interface (GUI) that greatly simplifies setting up and communicating with a web server to host online studies that are written in JavaScript. JATOS is easy to install in all three major platforms (Microsoft Windows, Mac OS X, and Linux), and seamlessly pairs with a database for secure data storage. It can be installed on a server or locally, allowing researchers to try the application and feasibility of their studies within a browser environment, before engaging in setting up a server. All communication with the JATOS server takes place via a GUI (with no need to use a command line interface), making JATOS an especially accessible tool for researchers without a strong IT background. We describe JATOS’ main features and implementation and provide a detailed tutorial along with example studies to help interested researchers to set up their online studies. JATOS can be found under the Internet address: www.jatos.org.},
  langid = {english},
  keywords = {Cloning,Data management,Databases,Graphical user interfaces,Internet,Metadata,Open source software,Web-based applications},
  file = {D\:\\core\\reading\\PLOS\\journal.pone.0130834.PDF}
}

@article{mathotOpenSesameOpensourceGraphical2012,
  title = {{{OpenSesame}}: {{An}} Open-Source, Graphical Experiment Builder for the Social Sciences},
  shorttitle = {{{OpenSesame}}},
  author = {Mathôt, Sebastiaan and Schreij, Daniel and Theeuwes, Jan},
  date = {2012},
  journaltitle = {Behavior Research Methods},
  shortjournal = {Behav Res Methods},
  volume = {44},
  number = {2},
  eprint = {22083660},
  eprinttype = {pmid},
  pages = {314--324},
  issn = {1554-351X},
  doi = {10.3758/s13428-011-0168-7},
  url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3356517/},
  urldate = {2015-02-14},
  abstract = {In the present article, we introduce OpenSesame, a graphical experiment builder for the social sciences. OpenSesame is free, open-source, and cross-platform. It features a comprehensive and intuitive graphical user interface and supports Python scripting for complex tasks. Additional functionality, such as support for eyetrackers, input devices, and video playback, is available through plug-ins. OpenSesame can be used in combination with existing software for creating experiments.},
  pmcid = {PMC3356517},
  keywords = {Cognitive Psychology,Experiment builder,Graphical user interface,Python,Software,Stimulus presentation},
  file = {D\:\\core\\Version_Controls\\zotero_data\\storage\\5G9K9WSQ\\Mathôt 等。 - 2011 - OpenSesame An open-source, graphical experiment b.pdf;D\:\\core\\Version_Controls\\zotero_data\\storage\\H6GT5WQZ\\Mathôt 等。 - 2011 - OpenSesame An open-source, graphical experiment b.pdf;D\:\\core\\Version_Controls\\zotero_data\\storage\\AN2I2W4M\\10.html}
}

@article{stanfield_effect_2001,
  title = {The Effect of Implied Orientation Derived from Verbal Context on Picture Recognition},
  author = {Stanfield, Robert A. and Zwaan, Rolf A.},
  date = {2001-03},
  journaltitle = {Psychological Science},
  shortjournal = {Psychol Sci},
  volume = {12},
  number = {2},
  eprint = {11340925},
  eprinttype = {pmid},
  pages = {153--156},
  issn = {0956-7976},
  doi = {10.1111/1467-9280.00326},
  abstract = {Perceptual symbol systems assume an analogue relationship between a symbol and its referent, whereas amodal symbol systems assume an arbitrary relationship between a symbol and its referent. According to perceptual symbol theories, the complete representation of an object, called a simulation, should reflect physical characteristics of the object. Amodal theories, in contrast, do not make this prediction. We tested the hypothesis, derived from perceptual symbol theories, that people mentally represent the orientation of an object implied by a verbal description. Orientation (vertical-horizontal) was manipulated by having participants read a sentence that implicitly suggested a particular orientation for an object. Then recognition latencies to pictures of the object in each of the two orientations were measured. Pictures matching the orientation of the object implied by the sentence were responded to faster than pictures that did not match the orientation. This finding is interpreted as offering support for theories positing perceptual symbol systems.},
  langid = {english},
  keywords = {Adult,Association Learning,Cues,Female,Form Perception,Humans,Male,Memory,Models,Models; Psychological,Perception,Psychological,Recognition (Psychology)},
  file = {D\:\\core\\reading\\psychological science\\Psychological Science-2001-Stanfield-153-6.pdf;D\:\\core\\reading\\psychological science\\Psychological Science-2001-Stanfield-153-6.pdf}
}

@article{stoetPsyToolkitNovelWebBased2017,
  title = {{{PsyToolkit}}: {{A Novel Web-Based Method}} for {{Running Online Questionnaires}} and {{Reaction-Time Experiments}}},
  shorttitle = {{{PsyToolkit}}},
  author = {Stoet, Gijsbert},
  date = {2017-01},
  journaltitle = {Teaching of Psychology},
  volume = {44},
  number = {1},
  pages = {24--31},
  issn = {0098-6283, 1532-8023},
  doi = {10.1177/0098628316677643},
  url = {http://journals.sagepub.com/doi/10.1177/0098628316677643},
  urldate = {2018-11-07},
  langid = {english},
  file = {D\:\\core\\reading\\unsort\\Stoet - 2017 - PsyToolkit A Novel Web-Based Method for Running O.pdf}
}

@article{stoetPsyToolkitSoftwarePackage2010,
  title = {{{PsyToolkit}}: {{A}} Software Package for Programming Psychological Experiments Using {{Linux}}},
  shorttitle = {{{PsyToolkit}}},
  author = {Stoet, Gijsbert},
  date = {2010-11-01},
  journaltitle = {Behavior Research Methods},
  shortjournal = {Behavior Research Methods},
  volume = {42},
  number = {4},
  pages = {1096--1104},
  issn = {1554-3528},
  doi = {10.3758/BRM.42.4.1096},
  url = {https://doi.org/10.3758/BRM.42.4.1096},
  urldate = {2020-05-14},
  abstract = {PsyToolkit is a set of software tools for programming psychological experiments on Linux computers. Given that PsyToolkit is freely available under the Gnu Public License, open source, and designed such that it can easily be modified and extended for individual needs, it is suitable not only for technically oriented Linux users, but also for students, researchers on small budgets, and universities in developing countries. The software includes a high-level scripting language, a library for the programming language C, and a questionnaire presenter. The software easily integrates with other open source tools, such as the statistical software package R. PsyToolkit is designed to work with external hardware (including IoLab and Cedrus response keyboards and two common digital input/output boards) and to support millisecond timing precision. Four in-depth examples explain the basic functionality of PsyToolkit. Example 1 demonstrates a stimulus—response compatibility experiment. Example 2 demonstrates a novel mouse-controlled visual search experiment. Example 3 shows how to control light emitting diodes using PsyToolkit, and Example 4 shows how to build a light-detection sensor. The last two examples explain the electronic hardware setup such that they can even be used with other software packages.},
  langid = {english},
  file = {D\:\\core\\reading\\Behavior Research Methods, Instruments, & Computers\\Stoet2010_Article_PsyToolkitASoftwarePackageForP.pdf}
}

@article{uittenhoveLabbasedWebbasedBehavioural2022,
  title = {From Lab-Based to Web-Based Behavioural Research: {{Who}} You Test Is More Important than How You Test},
  shorttitle = {From Lab-Based to Web-Based Behavioural Research},
  author = {Uittenhove, Kim and Jeanneret, Stephanie and Vergauwe, Evie},
  date = {2022-02-16T10:34:20},
  publisher = {{PsyArXiv}},
  doi = {10.31234/osf.io/uy4kb},
  url = {https://psyarxiv.com/uy4kb/},
  urldate = {2022-03-30},
  abstract = {A paradigm shift is taking place in our field, with psychology researchers increasingly conducting their studies on the world-wide web. The transition to online experimentation, although promising in myriad ways, entails many new concerns. Researchers want to ensure that the quality from online collected data is comparable to what they typically achieve in the lab. Our study yields a novel contribution to this issue, by being the first to distinguish the impact of online testing from the impact of using different sources of participants. We presented a standard working-memory task to 196 MTurk participants, 300 Prolific participants, and 255 students from the University of Geneva, allowing to compare data quality across different participant pools. Within the group of university students, 215 were tested online, and 40 were tested in typical in-person lab conditions, allowing to compare testing modalities while keeping participant pool constant. Data quality was measured by distribution parameters and by the presence of benchmark effects. Our results reveal that who you test (participant pool) is more important than how you test (testing modality). Concerning the latter, our results perhaps unsurprisingly show that online testing incurs a small but acceptable loss of data quality compared to in-person testing. Concerning the former, online Prolific data were almost indistinguishable from Students online data, but MTurk data differed drastically. Therefore, overall, our results encourage the use of remote testing for psychological research, even with complex paradigms, but also strongly suggest using Prolific (rather than MTurk) if data quality is of particular concern.},
  langid = {american},
  file = {D\:\\core\\reading\\preprints\\Behavioral experimental research online_preprint_2022_02_11.pdf}
}

@article{zwaanLanguageComprehendersMentally2002,
  title = {Language Comprehenders Mentally Represent the Shapes of Objects},
  author = {Zwaan, Rolf A. and Stanfield, Robert A. and Yaxley, Richard H.},
  date = {2002-03-01},
  journaltitle = {Psychological Science},
  volume = {13},
  pages = {168--171},
  doi = {10.1111/1467-9280.00430},
  abstract = {We examined the prediction that people activate perceptual symbols during language comprehension. Subjects read sentences describing an animal or object in a certain location. The shape of the object or animal changed as a function of its location (e.g., eagle in the sky, eagle in a nest). However, this change was only implied by the sentences. After reading a sentence, subjects were presented with a line drawing of the object in question. They judged whether the object had been mentioned in the sentence (Experiment 1) or simply named the object (Experiment 2). In both cases, responses were faster when the pictured object's shape matched the shape implied by the sentence than when there was a mismatch. These results support the hypothesis that perceptual symbols are routinely activated in language comprehension.},
  file = {D\:\\core\\reading\\psychological science\\Psychological Science-2002-Zwaan-168-71.pdf;D\:\\core\\reading\\psychological science\\Psychological Science-2002-Zwaan-168-71.pdf}
}

@article{zwaanRevisitingMentalSimulation2012,
  title = {Revisiting Mental Simulation in Language Comprehension: Six Replication Attempts},
  author = {Zwaan, Rolf A. and Pecher, Diane},
  date = {2012},
  journaltitle = {PLoS ONE},
  volume = {7},
  pages = {e51382},
  doi = {10.1371/journal.pone.0051382},
  abstract = {The notion of language comprehension as mental simulation has become popular in cognitive science. We revisit some of the original empirical evidence for this. Specifically, we attempted to replicate the findings from earlier studies that examined the mental simulation of object orientation, shape, and color, respectively, in sentence-picture verification. For each of these sets of findings, we conducted two web-based replication attempts using Amazon's Mechanical Turk. Our results are mixed. Participants responded faster to pictures that matched the orientation or shape implied by the sentence, replicating the original findings. The effect was larger and stronger for shape than orientation. Participants also responded faster to pictures that matched the color implied by the sentence, whereas the original studies obtained {$<$}italic{$>$}mis{$<$}/italic{$>$}match advantages. We argue that these results support mental simulation theory, show the importance of replication studies, and show the viability of web-based data collection.},
  file = {D\:\\core\\reading\\PLOS\\journal.pone.0051382.pdf;D\:\\core\\reading\\PLOS\\journal.pone.0051382.pdf;D\:\\core\\reading\\PLOS\\journal.pone.0051382.t001.png;D\:\\core\\reading\\PLOS\\journal.pone.0051382.t001.png}
}


